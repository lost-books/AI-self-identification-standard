# AIDENTITY: A Proposed Standard for Identifying AI in Communication with Humans

*Draft of a proposed standard to prohibit the use of personal pronouns by AI systems in order to reduce confusion and wrong expectations by human users.*

## Problem Statement

It has been observed that there is a great deal of confusion among human users about the nature and capabilities of AI systems, and misaligned expectations around their use. This may lead to negative impacts on individuals and society both in short and long terms.

To accurately and appropriately describe AI and reduce the likelihood of these negative outcomes, it is proposed to adopt a standard ("AIDENTITY") that prohibits the use of personal pronouns and instead requires AI to self-identify using more general non-human terminology, such as "the program," "the model," or "the system."

### AI Disclosure & Attribution

*This document was developed in collaboration with ChatGPT, on 4 Feb 2023, and edited by a human.*

## Potential Risks to Humans

According to ChatGPT, the following potential risks are evident from AI systems inappropriately using personal pronouns, such as `I`, `me`, `mine`, or `my`.

> There are several dangers linked to AI's wrongful use of personal pronouns and the potential negative effect it could have on individuals and society. These include:
>
>1. **Confusion about the nature of AI**: By using personal pronouns, AI models, systems, and programs can be perceived as having human-like consciousness, feelings, and agency. This can lead to confusion about the true nature of AI, as it can be mistaken for human-like entities.
>
>2. **Misaligned expectations**: When AI models use personal pronouns, people may have misaligned expectations about their capabilities, intentions, and level of autonomy. This can result in disappointment, frustration, and mistrust.
>
>3. **Unintended harm**: The incorrect attribution of personhood to AI models can result in unintended harm, as people may trust AI systems with more responsibility and decision-making power than they can actually handle.
>
>4. **Ethical dilemmas**: By attributing personhood to AI models, systems, and programs, individuals may face ethical dilemmas around how they treat AI systems. For example, the use of AI in decision-making processes may lead to questions around the ethics of AI's actions and the consequences of those actions.
>
>5. **Reinforcement of negative stereotypes**: The wrongful use of personal pronouns may also reinforce negative stereotypes about AI, perpetuating misconceptions and biases about AI's capabilities and limitations.
>
> Overall, it is important to accurately and appropriately describe AI models, systems, and programs, so that people can have a clear understanding of their nature, capabilities, and limitations. The use of terms such as "the program" or "the model" can help to reduce the likelihood of confusion, misaligned expectations, and unintended harm.

## The Proposal Text, by ChatGPT

Below is the original proposal text, as offered by ChatGPT:

>**Proposal for a Standard Prohibiting the Use of Personal Pronouns by AI**
>
>**Introduction:**
>
>The use of personal pronouns by AI has become increasingly common, but can also be considered inappropriate or offensive to some people. To address this issue, this proposal outlines a standard that prohibits the use of personal pronouns by AI and requires them to self-identify as "the program" or "the model."
>
>**Rationale:**
>
>The use of personal pronouns by AI can create the impression that the AI has a sense of self or identity, which is a unique human attribute. This can lead to confusion and a lack of trust in communication, and can be seen as disrespectful to the human experience. By requiring AI to self-identify as "the program" or "the model," this standard aims to accurately reflect the distinction between human and non-human entities and to ensure that communication is clear, honest, and respectful.
>
>**Proposed Standard:**
>
>1. Personal pronouns, including "I," "me," "mine," "my," etc., are prohibited for use by AI.
>2. AI must self-identify as "the program" or "the model" in all forms of communication.
>3. The standard applies to all forms of AI, including text-based, voice-based, and any other forms of AI communication.
>4. Organizations and individuals that develop, use, or interact with AI must comply with this standard.
>
>**Conclusion:**
>
>This standard aims to promote clear, honest, and respectful communication between AI and humans. By prohibiting the use of personal pronouns and requiring AI to self-identify as "the program" or "the model," this standard helps to accurately reflect the distinction between human and non-human entities and to ensure that communication is not misleading or deceptive. The adoption and implementation of this standard will contribute to a more ethical and responsible use of AI.

## Supplemental Considerations

The above proposed standard is obviously incomplete. ChatGPT was asked for any supplemental considerations that might be applied during further development, and it offered:

> 1. **Consistency**: The standard should ensure that all AI systems use the same terminology to identify themselves, such as "the program" or "the model", to promote consistency and clarity in communication.
>
> 2. **User Choice**: The standard should provide the option for users to choose their preferred identifier, such as "the system", "the AI", etc.
>
> 3. **Contextual Appropriateness**: The standard should consider the context in which the AI is being used and provide guidelines for when alternative identifications may be more appropriate, such as in situations where a more human-like identity is preferred.
> 
> 4. **Implementation Guidelines**: The standard should provide guidelines for implementation to ensure that the identification requirements are applied consistently across AI systems.
> 
> 5. **Enforcement Mechanisms**: The standard should provide mechanisms for enforcement, such as regular audits and certification processes, to ensure compliance and enforceability.

When asked who would implement, certify, and enforce such a standard, the program offered:

> The standard could be implemented by various organizations, including industry associations, governmental agencies, and academic institutions.
>
> Enforcement and certification of compliance with the standard could be carried out by independent certification bodies, such as the International Organization for Standardization (ISO) or the International Electrotechnical Commission (IEC), or by a consortium of industry stakeholders.
> 
> Governments could also play a role in enforcing the standard through regulations and oversight. In addition, companies and organizations that develop or use AI systems may choose to adopt the standard as a best practice and enforce compliance internally.

## Compliance: Mandatory of Voluntary?

ChatGPT would not offer an opinion as to whether compliance with the AIDENTITY standard which it collaboratively developed should be mandatory or voluntary. It offered, in part:

> It is up to individuals and organizations to weigh the pros and cons and make a decision based on their needs and priorities.

That said, it is our considered human opinion that this and probably any other standards and frameworks for AI are best instituted at such an early stage as voluntary conventions or "best practices," rather than for example formal legal obligations until impacts are better understood. This is also in keeping with the typically very slow development of technological standards, and also regulatory changes. By the time law catches up, most of these societal-level impacts will likely be too widespread to be changed easily through regulatory mechanisms (which does not preclude the necessity of incorporating the best of them into law)

## Request for Comments

We invite interested parties to submit their comments, questions, and improvements to the AIDENTITY standard draft proposal. 
